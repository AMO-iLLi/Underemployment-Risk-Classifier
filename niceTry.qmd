---
title: "niceTry"
format: html
---


```{r}
# -------------------------------
# Load libraries
# -------------------------------
library(tidyverse)
library(xgboost)
library(caret)

# -------------------------------
# Read datasets
# -------------------------------
train_set <- read_csv("train.csv", 
                      col_types = cols(
                        id       = col_double(),
                        CERTLEVP = col_factor(),
                        PGMCIPAP = col_factor(),
                        PGM_P034 = col_factor(),
                        PGM_P036 = col_factor(),
                        HLOSGRDP = col_factor(),
                        PREVLEVP = col_factor(),
                        PGM_280A = col_factor(),
                        PGM_280B = col_factor(),
                        PGM_280C = col_factor(),
                        PGM_280F = col_factor(),
                        PGM_P401 = col_factor(),
                        STULOANS = col_factor(),
                        DBTOTGRD = col_factor(),
                        SCHOLARP = col_factor(),
                        GRADAGEP = col_factor(),
                        GENDER2  = col_factor(),
                        CTZSHIPP = col_factor(),
                        VISBMINP = col_factor(),
                        DDIS_FL  = col_factor(),
                        PAR1GRD  = col_factor(),
                        PAR2GRD  = col_factor(),
                        BEF_P140 = col_factor(),
                        BEF_160  = col_double()
                      ))

test_set <- read_csv("test.csv", 
                     col_types = cols(
                        id       = col_double(),
                        CERTLEVP = col_factor(),
                        PGMCIPAP = col_factor(),
                        PGM_P034 = col_factor(),
                        PGM_P036 = col_factor(),
                        HLOSGRDP = col_factor(),
                        PREVLEVP = col_factor(),
                        PGM_280A = col_factor(),
                        PGM_280B = col_factor(),
                        PGM_280C = col_factor(),
                        PGM_280F = col_factor(),
                        PGM_P401 = col_factor(),
                        STULOANS = col_factor(),
                        DBTOTGRD = col_factor(),
                        SCHOLARP = col_factor(),
                        GRADAGEP = col_factor(),
                        GENDER2  = col_factor(),
                        CTZSHIPP = col_factor(),
                        VISBMINP = col_factor(),
                        DDIS_FL  = col_factor(),
                        PAR1GRD  = col_factor(),
                        PAR2GRD  = col_factor(),
                        BEF_P140 = col_factor(),
                        BEF_160  = col_double()
                     ))

# -------------------------------
# Selected features (from RF importance)
# -------------------------------
vars_keep <- c(
  "CERTLEVP", "PGMCIPAP", "PGM_P034", "PGM_P036", "PGM_280A", "PGM_280B", "PGM_P401",
  "STULOANS", "SCHOLARP", "PREVLEVP", "HLOSGRDP", "GRADAGEP",
  "PAR1GRD", "PAR2GRD", "BEF_P140", "BEF_160",
  "CTZSHIPP", "GENDER2"
)

# -------------------------------
# Encode categorical variables as integers
# -------------------------------
categorical_cols <- vars_keep[sapply(train_set[vars_keep], is.factor)]

for(col in categorical_cols){
  # Combine train and test levels to avoid mismatch
  levels_all <- union(levels(train_set[[col]]), levels(test_set[[col]]))
  
  train_set[[col]] <- as.integer(factor(train_set[[col]], levels = levels_all)) - 1
  test_set[[col]]  <- as.integer(factor(test_set[[col]], levels = levels_all)) - 1
}

# -------------------------------
# Prepare matrices for XGBoost
# -------------------------------
X_train <- as.matrix(train_set %>% select(all_of(vars_keep)))
y_train <- as.numeric(as.character(train_set$overqualified))  # 0/1 target

X_test <- as.matrix(test_set %>% select(all_of(vars_keep)))

dtrain <- xgb.DMatrix(data = X_train, label = y_train)

# -------------------------------
# XGBoost parameters
# -------------------------------
params <- list(
  objective = "binary:logistic",
  eval_metric = "auc",
  max_depth = 6,
  eta = 0.1,
  subsample = 0.8,
  colsample_bytree = 0.8
)

# -------------------------------
# Cross-validation to find best nrounds
# -------------------------------
cv <- xgb.cv(
  params = params,
  data = dtrain,
  nrounds = 500,
  nfold = 5,
  early_stopping_rounds = 10,
  verbose = 1
)

best_nrounds <- cv$best_iteration
cat("Best nrounds:", best_nrounds, "\n")

# -------------------------------
# Train final model on all train data
# -------------------------------
xgb_model <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = best_nrounds
)

# -------------------------------
# Make predictions on test set
# -------------------------------
xgb_pred_prob <- predict(xgb_model, X_test)         # predicted probabilities
xgb_pred <- ifelse(xgb_pred_prob > 0.5, 1, 0)      # convert to 0/1

# Add predictions to test_set
test_set$overqualified_pred <- xgb_pred
test_set$overqualified_prob <- xgb_pred_prob

# View first few predictions
head(test_set %>% select(id, overqualified_pred, overqualified_prob))

write_csv(test_set %>% select(id, overqualified_pred), "submission.csv")

```

